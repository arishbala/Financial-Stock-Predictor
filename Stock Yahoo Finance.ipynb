{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Financial Profit With ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing  libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Dataset to download it from the web and Pre process the dataset. APPL variable can be changed to any ticker on the stock market to get you the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(AAPL, n_steps=50, scale=True, shuffle=True, lookup_step=30, split_by_date=True,\n",
    "                test_size=0.50, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(AAPL, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(AAPL)\n",
    "    elif isinstance(AAPL, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = AAPL\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=400, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish Parameters to train the model. Can be adjusted accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 30\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.25 is 25%\n",
    "TEST_SIZE = 0.50\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 300 LSTM neurons\n",
    "UNITS = 400\n",
    "# 20% dropout\n",
    "DROPOUT = 0.2\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 74\n",
    "EPOCHS = 10\n",
    "# APPlE stock market\n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Function Below to train the Model Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Dataframe for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 122.38$\n",
      "huber_loss loss: 0.00012213108129799366\n",
      "Mean Absolute Error: 1.131746840151875\n",
      "Accuracy score: 0.5376685170499603\n",
      "Total buy profit: 799.5410524532199\n",
      "Total sell profit: -683.7215654924512\n",
      "Total profit: 115.8194869607687\n",
      "Profit per trade: 0.0459236665189408\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  open        high         low       close    adjclose  \\\n",
      "2021-01-22  136.279999  139.850006  135.020004  139.070007  138.862503   \n",
      "2021-01-29  135.830002  136.740005  130.210007  131.960007  131.763107   \n",
      "2021-02-03  135.759995  135.770004  133.610001  133.940002  133.740158   \n",
      "2021-02-09  136.619995  137.880005  135.850006  136.009995  136.009995   \n",
      "2021-02-10  136.479996  136.990005  134.399994  135.389999  135.389999   \n",
      "2021-02-16  135.490005  136.009995  132.789993  133.190002  133.190002   \n",
      "2021-02-17  131.250000  132.220001  129.470001  130.839996  130.839996   \n",
      "2021-02-19  130.240005  130.710007  128.800003  129.869995  129.869995   \n",
      "2021-02-24  124.940002  125.559998  122.230003  125.349998  125.349998   \n",
      "2021-02-25  124.680000  126.459999  120.540001  120.989998  120.989998   \n",
      "\n",
      "                 volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2021-01-22  114459400.0   AAPL   132.867844        135.369995         0.0   \n",
      "2021-01-29  177180600.0   AAPL   139.000885        126.000000         0.0   \n",
      "2021-02-03   89880900.0   AAPL   135.287033        120.989998         0.0   \n",
      "2021-02-09   76774200.0   AAPL   136.163086        122.059998         0.0   \n",
      "2021-02-10   73046600.0   AAPL   136.175354        120.129997         0.0   \n",
      "2021-02-16   80576300.0   AAPL   135.207291        121.089996         0.0   \n",
      "2021-02-17   97918500.0   AAPL   134.030838        119.980003         0.0   \n",
      "2021-02-19   87668800.0   AAPL   131.281845        121.029999         0.0   \n",
      "2021-02-24  111039900.0   AAPL   126.298752        124.760002         0.0   \n",
      "2021-02-25  148199500.0   AAPL   124.888092        120.529999         0.0   \n",
      "\n",
      "            sell_profit  \n",
      "2021-01-22     5.994659  \n",
      "2021-01-29    -7.237778  \n",
      "2021-02-03    -1.546875  \n",
      "2021-02-09    -0.153091  \n",
      "2021-02-10    -0.785355  \n",
      "2021-02-16    -2.017288  \n",
      "2021-02-17    -3.190842  \n",
      "2021-02-19    -1.411850  \n",
      "2021-02-24    -0.948753  \n",
      "2021-02-25    -3.898094  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this API is having some problems gathering data at the moment because the scrapper is unreliable. Will Fix this data source soon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
